{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pPuJgbxLC74u"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi, cos, sin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZcZOPl95wNq"
   },
   "source": [
    "# Eigenvalues and Eigenvectors\n",
    "\n",
    "Figure 4.4 of [Mathematics for Machine Learning](https://mml-book.github.io/) depicts five transformation matrices $\\mathbf{A}_1, \\ldots, \\mathbf{A}_5$ and their impact on a square grid of points, centred at the origin. Let's use `numpy.linalg.eig` to compute the eigenspectrum of each of these matrices.\n",
    "\n",
    "Note that the first array returned by `np.linalg.eig` are the eigenvalues, not necessarily ordered.\n",
    "The second array returned is an array where the *columns* are normalized (unit \"length\") eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yIFFxOorFYH0"
   },
   "source": [
    "## Expansion on one axis and compression on the other\n",
    "\n",
    "$$\\mathbf{A}_1 = \n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{2} & 0\\\\\n",
    "0 & 2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZd4JLqeEY3U"
   },
   "outputs": [],
   "source": [
    "A = np.array([[1/2, 0], [0, 2]])\n",
    "print(np.linalg.eig(A))\n",
    "print(np.linalg.det(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uV5lqXmE68xQ"
   },
   "source": [
    "Here we see that the direction of the two eigenvectors corresponds to the canonical basis in $\\mathbb{R}^2$. One axis is scaled by a factor of 2 and the other is scaled by a factor of 0.5 (i.e. it is squished).\n",
    "\n",
    "Because the determinant is 1, the transformation is area-preserving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lSRxAbtuKfDe"
   },
   "source": [
    "## Shearing\n",
    "\n",
    "$$\\mathbf{A}_2 = \n",
    "\\begin{bmatrix}\n",
    "1 & \\frac{1}{2}\\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNCdI0KsErOQ"
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 1/2], [0, 1]])\n",
    "print(np.linalg.eig(A))\n",
    "print(np.linalg.det(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AukmSUzl81rb"
   },
   "source": [
    "Here we see that the eigenvectors are collinear, indicating that the mapping only happens along one direction (the horizontal axis). The eigenvalue (1) is repeated.\n",
    "\n",
    "Again, the transformation is area-preserving as the determinant is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t33rFSgRKi-w"
   },
   "source": [
    "## Rotation\n",
    "\n",
    "$$\\mathbf{A}_3 = \n",
    "\\begin{bmatrix}\n",
    "\\cos\\left(\\frac{\\pi}{6}\\right) & - \\sin\\left( \\frac{\\pi}{6}\\right)\\\\\n",
    "\\sin\\left(\\frac{\\pi}{6}\\right) &  \\cos\\left( \\frac{\\pi}{6}\\right)\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAaq4yEOE78J"
   },
   "outputs": [],
   "source": [
    "A = np.array([[cos(pi/6), -sin(pi/6)], [sin(pi/6), cos(pi/6)]])\n",
    "print(np.linalg.eig(A))\n",
    "print(np.linalg.det(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBDHsdYu-fae"
   },
   "source": [
    "Here the matrix only has complex eigenvalues, reflecting that the mapping is a rotation. \n",
    "\n",
    "A rotation has to be volume preserving, so the determinant is again 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7So2oFXFa9p"
   },
   "source": [
    "## Collapses a two-dimensional domain into one dimension\n",
    "\n",
    "$$\\mathbf{A}_4 = \n",
    "\\begin{bmatrix}\n",
    "1 & -1\\\\\n",
    "-1 & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_G5ij47BJl9P"
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, -1], [-1, 1]])\n",
    "print(np.linalg.eig(A))\n",
    "print(np.linalg.det(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICnMqeKqBk0r"
   },
   "source": [
    "Since one eigenvalue is 0, the space in the direction of the corresponding eigenvector collapses, while space in the direction of the other eigenvector is stretched by a factor of 2.\n",
    "\n",
    "Since the two dimensional domain has been collapsed into a single dimension, the determinant is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6vennXvTK0j2"
   },
   "source": [
    "## Shear-and-stretch mapping that shrinks space \n",
    "\n",
    "$$\\mathbf{A}_5 = \n",
    "\\begin{bmatrix}\n",
    "1 & \\frac{1}{2}\\\\\n",
    "\\frac{1}{2} & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ErdHfF_K80_"
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 1/2], [1/2, 1]])\n",
    "print(np.linalg.eig(A))\n",
    "print(np.linalg.det(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSzksXqUKe1N"
   },
   "source": [
    "This mapping stretches space along one eigenvector by a factor of 1.5 and compresses it along the orthogonal eigenvector by a factor of 0.5.\n",
    "\n",
    "The determinant is 0.75 which means that overall the transformation shrinks space by 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KdedptImLKoH"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Use Matplotlib to approximately reproduce the plots in Figure 4.4 of [Mathematics for Machine Learning](https://mml-book.github.io/). This will require you to create 400 points in $\\mathbb{R}^2$. Check out `numpy.mgrid`. You could start with a loop, and then try to figure out a way to more efficiently apply the linear transformation to each of the points."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EigenvaluesAndEigenvectors.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
