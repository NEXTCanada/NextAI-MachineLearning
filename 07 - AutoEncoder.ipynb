{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribution: \n",
    "\n",
    "   * Most material is adapted from [Morvan Zhou's Tutorials](https://morvanzhou.github.io/tutorials/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoders\n",
    "\n",
    "We are going to apply what we've learned about supervised learning in PyTorch to construct our first unsupervised learning model, an AutoEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)    # make reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.005         # learning rate\n",
    "n_test_img = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mnist digits dataset\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalizes in the range [0.0, 1.0]\n",
    "    download=True,                                  # download it if you don't have it\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset consists of grayscale, 28x28 images of handwritten digits.\n",
    "\n",
    "The classic split is 60,000 training examples and 10,000 test examples.\n",
    "\n",
    "Let's have a look at some of the MNIST data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.train_data[0:100].view(100,1,28,28).size()\n",
    "\n",
    "print(train_data.train_data.size())     # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())   # (60000)\n",
    "\n",
    "n_toplot = 64\n",
    "\n",
    "plt.imshow(torchvision.utils.make_grid(train_data.train_data[0:n_toplot].view(n_toplot,1,28,28), \n",
    "                                       nrow=int(np.sqrt(n_toplot))).numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a Data Loader to return batches of size `batch_size`. The size of each batch will be (`batch_size`, 1, 28, 28):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to define a classical \"bottleneck\"-style deep autoencoder which gradually reduces the dimensionality of the input until it is compressed to a 3-dimensional code, then gradually expands back to reconstruct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, 3),   # compress to 3 features which can be visualized in plt\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Sigmoid(),       # compress to a range (0, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoding = self.encoder(x)\n",
    "        decoding = self.decoder(encoding)\n",
    "        return encoding, decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder()\n",
    "print(autoencoder)\n",
    "\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# original data (first row) for viewing\n",
    "view_data = Variable(train_data.train_data[:n_test_img].view(-1, 28*28).type(torch.FloatTensor)/255.)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        b_x = Variable(x.view(-1, 28*28))   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(x.view(-1, 28*28))   # batch y, shape (batch, 28*28)\n",
    "        b_label = Variable(y)               # batch label\n",
    "\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "        loss = loss_func(decoded, b_y)      # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "\n",
    "        if step % 500 == 0 and epoch in [0, 5, num_epochs-1]:\n",
    "            print('epoch: ', epoch, '| train loss: %.4f' % loss.data[0])\n",
    "\n",
    "            # plotting decoded image (second row)\n",
    "            _, decoded_data = autoencoder(view_data)\n",
    "            \n",
    "            # initialize figure\n",
    "            f, a = plt.subplots(2, n_test_img, figsize=(5, 2))\n",
    "            \n",
    "            for i in range(n_test_img):\n",
    "                a[0][i].imshow(np.reshape(view_data.data.numpy()[i], (28, 28)), cmap='gray'); \n",
    "                a[0][i].set_xticks(()) \n",
    "                a[0][i].set_yticks(())\n",
    "    \n",
    "            for i in range(n_test_img):\n",
    "                a[1][i].clear()\n",
    "                a[1][i].imshow(np.reshape(decoded_data.data.numpy()[i], (28, 28)), cmap='gray')\n",
    "                a[1][i].set_xticks(()) \n",
    "                a[1][i].set_yticks(())\n",
    "            plt.show(); plt.pause(0.05)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the bottleneck layer is 3-d, we can visualize the data (here, the first 200 points) by projecting it to this space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vis = 200\n",
    "view_data = Variable(train_data.train_data[:n_vis].view(-1, 28*28).type(torch.FloatTensor)/255.)\n",
    "encoded_data, _ = autoencoder(view_data)\n",
    "fig = plt.figure(2); ax = Axes3D(fig)\n",
    "X, Y, Z = encoded_data.data[:, 0].numpy(), encoded_data.data[:, 1].numpy(), encoded_data.data[:, 2].numpy()\n",
    "values = train_data.train_labels[:n_vis].numpy()\n",
    "for x, y, z, s in zip(X, Y, Z, values):\n",
    "    c = cm.rainbow(int(255*s/9)); ax.text(x, y, z, s, backgroundcolor=c)\n",
    "ax.set_xlim(X.min(), X.max()); ax.set_ylim(Y.min(), Y.max()); ax.set_zlim(Z.min(), Z.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "1. Noting that the outputs are sigmoid, what happens when you use a binary cross entropy loss instead of MSE?\n",
    "\n",
    "2. Try changing from tanh to ReLU hidden units. Does this make a difference?\n",
    "\n",
    "3. Implement a denoising autoencoder.\n",
    "\n",
    "4. Implement a contractive autoencoder. The tricky part here is implementing the loss term based on the Frobenius norm of the Jacobian. [Agustinus Kristiadi's Blog](https://wiseodd.github.io/techblog/2016/12/05/contractive-autoencoder/) gives a nice derivation of this term and what it looks like in code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
